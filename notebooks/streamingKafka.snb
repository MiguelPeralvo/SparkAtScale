{
  "metadata" : {
    "name" : "Ratings from Kafka1",
    "user_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "auto_save_timestamp" : "1970-01-01T00:00:00.000Z",
    "language_info" : {
      "name" : "scala",
      "file_extension" : "scala",
      "codemirror_mode" : "text/x-scala"
    },
    "trusted" : true,
    "customLocalRepo" : "/home/automaton/.ivy2",
    "customRepos" : null,
    "customDeps" : [ "com.datastax.spark:spark-cassandra-connector_2.10:1.4.0-M3", "org.apache.spark:spark-streaming-kafka_2.10:1.4.1", "org.apache.spark % spark-graphx_2.10 % 1.4.1", "- org.apache.spark % spark-core_2.10 % _", "- org.apache.spark % spark-streaming_2.10 % _", "- org.apache.hadoop % _ % _" ],
    "customImports" : null,
    "customArgs" : null,
    "customSparkConf" : {
      "spark.cassandra.connection.host" : "172.31.2.143",
      "spark.master" : "spark://172.31.2.143:7077",
      "spark.executor.cores" : "1",
      "spark.executor.memory" : "512m",
      "spark.cores.max" : "1",
      "spark.eventLog.enabled" : "true",
      "spark.eventLog.dir" : "logs/spark"
    }
  },
  "cells" : [ {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "# Setup (boilerplate)"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val sqlContext = new org.apache.spark.sql.SQLContext(sparkContext)\nimport sqlContext.implicits._\nimport org.apache.spark.sql.functions._\n",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@236bb8d\nimport sqlContext.implicits._\nimport org.apache.spark.sql.functions._\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 1
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Creating the domain object"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "case class Rating(user_id: Int, movie_id: Int, rating: Float, batchtime:Long) {\n  def toCSV=s\"$user_id,$rating,$movie_id\"\n}",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "defined class Rating\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 2
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "# Viz"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Reactive list of data (capped at 20 elements)"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "val list = ul(20)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "list: notebook.front.DataConnectedWidget[String]{implicit val singleCodec: notebook.Codec[play.api.libs.json.JsValue,String]; def data: Seq[String]; def data_=(x$1: Seq[String]): Unit; lazy val toHtml: scala.xml.Elem; def append(s: String): Unit; def appendAll(s: Seq[String]): Unit} = <anon$1 widget>\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<ul data-bind=\"foreach: value\">\n      <li data-bind=\"text: $data\"></li><script data-this=\"{&quot;valueId&quot;:&quot;anona83004710252105c524bd0d9d9300cd5&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/\nreq(\n['observable', 'knockout'],\nfunction (O, ko) {\n  ko.applyBindings({\n      value: O.makeObservable(valueId)\n    },\n    this\n  );\n});\n          /*]]>*/</script></ul>"
      },
      "output_type" : "execute_result",
      "execution_count" : 3
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "### Reactive line plot"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "val line = widgets.LineChart[Seq[(Long, Double)]](Seq.empty[(Long, Double)], fields=Some((\"X\", \"Y\")), maxPoints=100)",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "# Spark Streaming consuming Kafka"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "The context and kafka conf"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.streaming.Seconds\nimport org.apache.spark.streaming.StreamingContext\n\nval ssc = new StreamingContext(sc, Seconds(2))\nval brokers = \"172.31.4.32:9092\"\nval topics = Set(\"ratings\")\nval kafkaParams = Map[String, String](\"metadata.broker.list\" -> brokers)",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "import org.apache.spark.streaming.Seconds\nimport org.apache.spark.streaming.StreamingContext\nssc: org.apache.spark.streaming.StreamingContext = org.apache.spark.streaming.StreamingContext@5a850040\nbrokers: String = 172.31.4.32:9092\ntopics: scala.collection.immutable.Set[String] = Set(ratings)\nkafkaParams: scala.collection.immutable.Map[String,String] = Map(metadata.broker.list -> 172.31.4.32:9092)\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : "<div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon20f1447c9d07fe8251eb2f6c9eebabac&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:&quot;metadata.broker.list&quot;,&quot;Y&quot;:&quot;172.31.4.32:9092&quot;}],&quot;genId&quot;:&quot;708850035&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tabs'], \n      function(playground, _magictabs) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictabs,\n    \"o\": {}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    <div>\n        <ul class=\"nav nav-tabs\" id=\"ul708850035\"><li>\n              <a href=\"#tab708850035-0\"><i class=\"fa fa-table\"/></a>\n            </li><li>\n              <a href=\"#tab708850035-1\"><i class=\"fa fa-pie-chart\"/></a>\n            </li></ul>\n\n        <div class=\"tab-content\" id=\"tab708850035\"><div class=\"tab-pane\" id=\"tab708850035-0\">\n            <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon71b81876d7c17982b6b7b2b9a7848e83&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:&quot;metadata.broker.list&quot;,&quot;Y&quot;:&quot;172.31.4.32:9092&quot;}],&quot;genId&quot;:&quot;748552508&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/tableChart'], \n      function(playground, _magictableChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magictableChart,\n    \"o\": {\"headers\":[\"X\",\"Y\"],\"nrow\":1,\"shown\":1,\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div>\n            </div><div class=\"tab-pane\" id=\"tab708850035-1\">\n            <div>\n      <script data-this=\"{&quot;dataId&quot;:&quot;anon3b1a40c5b3d824d42345d02e42b427ad&quot;,&quot;dataInit&quot;:[{&quot;X&quot;:&quot;metadata.broker.list&quot;,&quot;Y&quot;:&quot;172.31.4.32:9092&quot;}],&quot;genId&quot;:&quot;551870968&quot;}\" type=\"text/x-scoped-javascript\">/*<![CDATA[*/req(['../javascripts/notebook/playground','../javascripts/notebook/magic/pieChart'], \n      function(playground, _magicpieChart) {\n        // data ==> data-this (in observable.js's scopedEval) ==> this in JS => { dataId, dataInit, ... }\n        // this ==> scope (in observable.js's scopedEval) ==> this.parentElement ==> div.container below (toHtml)\n\n        playground.call(data,\n                        this\n                        ,\n                        {\n    \"f\": _magicpieChart,\n    \"o\": {\"series\":\"X\",\"p\":\"Y\",\"width\":600,\"height\":400}\n  }\n  \n                        \n                        \n                      );\n      }\n    );/*]]>*/</script>\n    </div>\n            </div></div>\n      </div></div>"
      },
      "output_type" : "execute_result",
      "execution_count" : 4
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "Biz:\n* Consuming Kafka, \n* creating Ratings, \n* computing moving average\n* update list and line plot"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "import org.apache.spark.streaming.kafka.KafkaUtils\nimport org.apache.spark.streaming.Time\nimport kafka.serializer.StringDecoder\nimport org.joda.time.DateTime\nimport org.apache.spark.sql.SaveMode\nimport sqlContext.implicits._\n\n val ratingsStream = KafkaUtils.createDirectStream[String, String, StringDecoder, StringDecoder](ssc, kafkaParams, topics)\n\n    ratingsStream.foreachRDD {\n      (message: RDD[(String, String)], batchTime: Time) => {\n        // convert each RDD from the batch into a Ratings DataFrame\n        //rating data has the format user_id:movie_id:rating:timestamp\n        val df = message.map {\n          case (key, nxtRating) => nxtRating.split(\"::\")\n        }.map(rating => {\n          val timestamp: Long = new DateTime(rating(3).trim.toLong).getMillis\n          Rating(rating(0).trim.toInt, rating(1).trim.toInt, rating(2).trim.toFloat, timestamp)\n        } ).toDF(\"user_id\", \"movie_id\", \"rating\", \"timestamp\")\n\n        // this can be used to debug dataframes\n        //if (debugOutput)\n        //  df.show()\n\n        // save the DataFrame to Cassandra\n        // Note:  Cassandra has been initialized through spark-env.sh\n        //        Specifically, export SPARK_JAVA_OPTS=-Dspark.cassandra.connection.host=127.0.0.1\n        df.write.format(\"org.apache.spark.sql.cassandra\")\n          .mode(SaveMode.Append)\n          .options(Map(\"keyspace\" -> \"movie_db\", \"table\" -> \"rating_by_movie\"))\n          .save()\n        \n        list.appendAll(message.take(10).toList.map(_.toString))\n      }\n    }\n",
    "outputs" : [ {
      "name" : "stdout",
      "output_type" : "stream",
      "text" : "warning: there were 1 feature warning(s); re-run with -feature for details\nimport org.apache.spark.streaming.kafka.KafkaUtils\nimport org.apache.spark.streaming.Time\nimport kafka.serializer.StringDecoder\nimport org.joda.time.DateTime\nimport org.apache.spark.sql.SaveMode\nimport sqlContext.implicits._\nratingsStream: org.apache.spark.streaming.dstream.InputDStream[(String, String)] = org.apache.spark.streaming.kafka.DirectKafkaInputDStream@6bcffff1\n"
    }, {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 5
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "Start consuming"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : false
    },
    "cell_type" : "code",
    "source" : "ssc.start()",
    "outputs" : [ {
      "metadata" : { },
      "data" : {
        "text/html" : ""
      },
      "output_type" : "execute_result",
      "execution_count" : 6
    } ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "## Stop all"
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "Stop the streaming context (keeping the spark context up, just in case)"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "//ssc.stop(false) // commented in case of a Run All ^^",
    "outputs" : [ ]
  }, {
    "metadata" : { },
    "cell_type" : "markdown",
    "source" : "Stop the producer"
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "//stopSending = true // commented in case of a Run All ^^",
    "outputs" : [ ]
  }, {
    "metadata" : {
      "trusted" : true,
      "input_collapsed" : false,
      "collapsed" : true
    },
    "cell_type" : "code",
    "source" : "",
    "outputs" : [ ]
  } ],
  "nbformat" : 4
}